{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digging deeper into convolutional networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check out the first level of filters in a high-performing neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "neural_net = VGG16(include_top=False,\n",
    "                      input_shape=(224,224,3),\n",
    "                      pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conv_weights = neural_net.get_layer('block1_conv1').get_weights()\n",
    "for f in first_conv_weights:\n",
    "    print(f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many filters are there? What is their dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we treat filters as images themselves? Lets try!\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def filter2image(one_filter, resize=True):\n",
    "    '''Makes visualizing filters possible -- very crudely with poor normalization'''\n",
    "    one_filter += np.min(one_filter)\n",
    "    one_filter /= np.max(one_filter)\n",
    "    one_filter *= 255\n",
    "    one_filter = one_filter.astype(np.uint8)\n",
    "    one_filter = Image.fromarray(one_filter)\n",
    "    if resize:\n",
    "        one_filter = one_filter.resize((100,100))\n",
    "    return one_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get access to the first filter and display it...\n",
    "for filterc in range(64):\n",
    "    one_filter = # Display the filter weights\n",
    "    display(filter2image(one_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perhaps more interesting is visualizing the later-layer activations for some images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from util import load_images_for_neural_network\n",
    "test_images = ['coco_workshop/22.jpg', 'coco_workshop/23.jpg', 'coco_workshop/24.jpg', 'coco_workshop/25.jpg']\n",
    "\n",
    "images_for_nn = load_images_for_neural_network(test_images,\n",
    "                                               batch_size=4)\n",
    "extract_model = Model(inputs=neural_net.input,\n",
    "                      outputs=neural_net.get_layer('block1_conv1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = extract_model.predict_generator(images_for_nn,\n",
    "                                         steps=1,\n",
    "                                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkin: what do each of these dimensions correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters = 10\n",
    "for idx, t in enumerate(test_images):\n",
    "    my_image = Image.open(t)\n",
    "    display(my_image)\n",
    "    for filter_idx in range(n_filters):\n",
    "        c_filter = result[idx,:,:,filter_idx]\n",
    "        display(filter2image(c_filter, resize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about layers later-on in the processing pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_for_nn = load_images_for_neural_network(test_images,\n",
    "                                               batch_size=4)\n",
    "extract_model = Model(inputs=neural_net.input,\n",
    "                      outputs=neural_net.get_layer('block3_conv3').output)\n",
    "result = extract_model.predict_generator(images_for_nn,\n",
    "                                         steps=1,\n",
    "                                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkin: what do the dimensions represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters = 10\n",
    "for idx, t in enumerate(test_images):\n",
    "    my_image = Image.open(t)\n",
    "    display(my_image)\n",
    "    for filter_idx in range(n_filters):\n",
    "        c_filter = result[idx,:,:,filter_idx]\n",
    "        display(filter2image(c_filter, resize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
