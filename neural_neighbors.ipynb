{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "try:\n",
    "    from tqdm import tqdm_notebook\n",
    "except:\n",
    "    def tqdm_notebook(iterable):\n",
    "        return iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome!\n",
    "\n",
    "Before we begin, make sure you have the following files downloaded and unzipped in this directory\n",
    "\n",
    "[MSCOCO data](https://drive.google.com/file/d/1hJrp-vn44zKPNknmMkvlPvRf2qrErzmB/view?usp=sharing)\n",
    "[British Library data](https://drive.google.com/file/d/1bJ-l9HchOzLXIhCGecz0sS3arPhZoA1H/view?usp=sharing)\n",
    "\n",
    "you can run the following cell to check to make sure that you have this done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('coco_workshop/0.jpg'):\n",
    "    print(\"Please download the COCO workshop data.\")\n",
    "if not os.path.exists('bl_workshop/0.jpg'):\n",
    "    print(\"Please download the BL workshop data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see what files are in these folders!\n",
    "files = os.listdir('coco_workshop')\n",
    "print(files[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the workshop, we will show how to load an image into python using the python image library (PIL). We will also display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "file_path = 'coco_workshop/22.jpg'\n",
    "my_image = Image.open(file_path)\n",
    "display(my_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try a few fun filters out on the image!\n",
    "from PIL import ImageFilter\n",
    "\n",
    "modified_image = my_image.filter(ImageFilter.BLUR)\n",
    "display(modified_image)\n",
    "modified_image = my_image.filter(ImageFilter.EDGE_ENHANCE)\n",
    "display(modified_image)\n",
    "modified_image = my_image.filter(ImageFilter.FIND_EDGES)\n",
    "display(modified_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image_size = my_image.size\n",
    "print(my_image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that this image is 640 pixels wide by 427 pixels high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Images as Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To a computer, an image is simply a big list of numbers. In particular, a useful representation of the image is the Red-Green-Blue (RGB) space representation. In the same way a printer can use red, green, and blue ink to represent most colors, a computer can, too. For each \"pixel\" in the input image, there will be three values that express to the computer what color is should be: a red value, a green value, and a blue value. So -- an image can be represented by a long list of numbers: for each x coordinate and for each y coordinate there will be a R,G,B triple. [Image source](https://web.stanford.edu/class/cs101/image-1-introduction.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![How a computer represents an image](images/pixels.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image_array = np.asarray(my_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the dimensions of this array represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import isolate_channel\n",
    "red_intensity_map = isolate_channel(image_array, 0)\n",
    "blue_intensity_map = isolate_channel(image_array, 1)\n",
    "green_intensity_map = isolate_channel(image_array, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_map = Image.fromarray(red_intensity_map)\n",
    "green_map = Image.fromarray(green_intensity_map)\n",
    "blue_map = Image.fromarray(blue_intensity_map)\n",
    "display(my_image)\n",
    "display(red_map)\n",
    "display(green_map)\n",
    "display(blue_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do these images really combine to form the original?\n",
    "combined_map = red_intensity_map + green_intensity_map + blue_intensity_map\n",
    "combined_image = Image.fromarray(combined_map)\n",
    "display(combined_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 3: Image Representation 1: Average Color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One goal of computer vision is to come up with vector representations of images. Lets see if we can use the average color for an image as a representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path1 = 'coco_workshop/22.jpg'\n",
    "image_path2 = 'coco_workshop/23.jpg'\n",
    "image_path3 = 'coco_workshop/24.jpg'\n",
    "image1 = Image.open(image_path1)\n",
    "image2 = Image.open(image_path2)\n",
    "image3 = Image.open(image_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import compute_mean_color\n",
    "mean_red, mean_green, mean_blue = compute_mean_color(image1)\n",
    "print(mean_red, mean_green, mean_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import constant_color_image\n",
    "display(constant_color_image(mean_red, mean_green, mean_blue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [image_path1, image_path2, image_path3]:\n",
    "    print(\"Image: \" + path)\n",
    "    image = Image.open(path)\n",
    "    display(image)\n",
    "    mean_red, mean_green, mean_blue = compute_mean_color(image)\n",
    "    display(constant_color_image(mean_red, mean_green, mean_blue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get the mean color for all images!\n",
    "base_path = 'coco_workshop/'\n",
    "n_images = 5000\n",
    "all_means = np.empty((n_images, 3)) #indexed by image_idx, channel\n",
    "for idx in range(n_images):\n",
    "    fname = base_path + str(idx) + \".jpg\"\n",
    "    print(\"processing \" + fname)\n",
    "    image = Image.open(path)\n",
    "    mean_red, mean_green, mean_blue = compute_mean_color(image)\n",
    "    all_means[idx,0] = mean_red\n",
    "    all_means[idx,1] = mean_green\n",
    "    all_means[idx,2] = mean_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_means[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_means.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Nearest neighbor search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a vector representation of each image (specifically: our vector is of length 3, representing the average color) we can search for nearest neighbors of each image according to this representation. In this space, two images are similar if they have similar average colors. Is this a good notion of similarity? What could this potentially be used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [Annoy library](https://github.com/spotify/annoy/) to perform nearest neighbor search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to build an object that will let us perform nearest-neighbor search!\n",
    "from annoy import AnnoyIndex\n",
    "searcher = AnnoyIndex(3) # we need to give it the dimension of the representation\n",
    "# now, we need to insert each image...\n",
    "for idx in range(n_images):\n",
    "    searcher.add_item(idx, all_means[idx,:])\n",
    "searcher.build(10) # don't worry about the 10 -- it's an internal parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can search for nearest neighbors for images of different indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_of_first_image = searcher.get_nns_by_item(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neighbors_of_first_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 22\n",
    "neighbors_of_first_image = searcher.get_nns_by_item(image_idx, 10)\n",
    "print(\"Start image:\")\n",
    "fname = base_path + str(image_idx) + \".jpg\"\n",
    "image = Image.open(fname)\n",
    "display(image)\n",
    "r, g, b = compute_mean_color(image)\n",
    "display(constant_color_image(r,g,b))\n",
    "\n",
    "fname = base_path + str(idx) + \".jpg\"\n",
    "for idx in neighbors_of_first_image:\n",
    "    fname = base_path + str(idx) + \".jpg\"\n",
    "    image = Image.open(fname)\n",
    "    display(image)\n",
    "    r, g, b = compute_mean_color(image)\n",
    "    display(constant_color_image(r,g,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part : Using a Deep Neural Network to Represent Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the neural network library needs an in-order list of all files\n",
    "n_images = 5000\n",
    "base = 'coco_workshop/'\n",
    "all_files = []\n",
    "for idx in range(n_images):\n",
    "    all_files.append(base + str(idx) + '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of efficiency, we will be running MobileNet, which is a roughly 13-layer neural network designed for mobile applications. In practice, neural networks can be up to 1000 layers deep!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import load_images_for_neural_network\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "\n",
    "neural_net = MobileNet(include_top=False,\n",
    "                       input_shape=(224,224,3),\n",
    "                       pooling='avg')\n",
    "neural_net.summary()\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "images_for_nn = load_images_for_neural_network(all_files,\n",
    "                                               batch_size=64)\n",
    "\n",
    "representations = neural_net.predict_generator(images_for_nn,\n",
    "                                               steps=n_images/batch_size+1,\n",
    "                                               verbose=1)\n",
    "representations = representations[:5000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(representations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = AnnoyIndex(1024) # we need to give it the dimension of the representation\n",
    "# now, we need to insert each image...\n",
    "for idx in range(n_images):\n",
    "    searcher.add_item(idx, representations[idx,:])\n",
    "searcher.build(10) # don't worry about the 10 -- it's an internal parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 119\n",
    "neighbors_of_image, dists = searcher.get_nns_by_item(image_idx, 10,include_distances=True)\n",
    "print(\"Start image:\")\n",
    "fname = base_path + str(image_idx) + \".jpg\"\n",
    "image = Image.open(fname)\n",
    "display(image)\n",
    "\n",
    "fname = base_path + str(idx) + \".jpg\"\n",
    "for dist_idx, idx in enumerate(neighbors_of_image[1:]):\n",
    "    fname = base_path + str(idx) + \".jpg\"\n",
    "    image = Image.open(fname)\n",
    "    display(image)\n",
    "    print(\"Distance to original image = \" + str(dists[dist_idx+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
